{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aada936",
   "metadata": {},
   "source": [
    "# Titanic machine learning from disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981156b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.536683100Z",
     "start_time": "2024-11-20T20:02:21.475170400Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from itertools import product\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import BayesianRidge,LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "b970b976",
   "metadata": {},
   "source": [
    "## Un helper pour plot la correlation matrix d'un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "id": "b94402e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.564207400Z",
     "start_time": "2024-11-20T20:02:21.542199300Z"
    }
   },
   "source": [
    "def plot_correlation(df,annot=True):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    corr = df.corr()\n",
    "    sns.heatmap(corr, annot=annot,cmap=sns.color_palette(\"vlag\", as_cmap=True),cbar_kws={'shrink': .8},annot_kws={\"size\": 6} )\n",
    "    plt.title(\"Correlation Matrix Heatmap\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "93423adc",
   "metadata": {},
   "source": [
    "## Deux classes et un helper:\n",
    "- CustomFunctionTransformer(FunctionTransformer) est une classe enfant de FunctionTransformer qui hérite de sa classe parent mais à laquelle on greffe des attributs cols_in,cols_out\n",
    "- Func_To_Transformer est une classe qui a des attributs :\n",
    "    - func : la fonction à appliquer aux éléments des colonnes\n",
    "    - cols_in : les colonnes sur lesquelles appliquer func\n",
    "    - cols_out : le nom des colonnes en sortie de func appliquée à cols_in\n",
    "    - get_transformer (@property) : une instance de FunctionTransformer qui applique proprement func\n",
    "- le helper get_feature_names_from_column_transformer : renvoie les noms de colonnes après application du cColumnTransformer ct, avec des noms de colonnes en entrée \"input_features\"\n",
    "- le helper to_pandas qui remet au format DataFrame la sortie du columntransformer"
   ]
  },
  {
   "cell_type": "code",
   "id": "8a1721d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.615591400Z",
     "start_time": "2024-11-20T20:02:21.558198400Z"
    }
   },
   "source": [
    "class CustomFunctionTransformer(FunctionTransformer):\n",
    "    def __init__(self,func,cols_in,cols_out):\n",
    "        FunctionTransformer.__init__(self,func)\n",
    "        self.cols_in,self.cols_out=cols_in,cols_out\n",
    "        \n",
    "#écrire une class avec methode func,get_cols_in,get_cols_out\n",
    "class Func_To_Transformer():\n",
    "    def __init__(self,func,cols_in,cols_out):\n",
    "        self.func=func\n",
    "        self.size_in,self.size_out=len(cols_in),len(cols_out)\n",
    "        self.cols_in,self.cols_out=cols_in,cols_out\n",
    "    @property\n",
    "    def get_transformer(self):\n",
    "        def out_func(data):\n",
    "        # Handle pandas to numpy conversion\n",
    "            if isinstance(data, pd.DataFrame) or isinstance(data, pd.Series):\n",
    "                data = data.values\n",
    "            # Ensure data has the correct shape\n",
    "            if data.ndim != 2 or data.shape[1] != self.size_out:\n",
    "                data = data.reshape(data.shape[0], self.size_in)  # Reshape based on k_in\n",
    "            # Apply transformation function row-by-row and reshape output\n",
    "            transformed_data = np.array([self.func(row[0]) for row in data])\n",
    "            return transformed_data.reshape(data.shape[0], self.size_out)\n",
    "        return CustomFunctionTransformer(out_func,self.cols_in,self.cols_out)\n",
    "\n",
    "# Helper function to get feature names from a fitted ColumnTransformer including transformers that do not have the set_ouput(transform=\"pandas\") method\n",
    "def get_feature_names_from_column_transformer(ct, input_features):\n",
    "    feature_names = []\n",
    "    passthrough_columns = [col for col in input_features if not any(col in columns for _,_,columns in ct.transformers_)]\n",
    "    print(f\"passthrough columns={passthrough_columns}\")\n",
    "\n",
    "    for name, transformer, columns in ct.transformers_:\n",
    "        if transformer == 'passthrough':\n",
    "            # If passthrough, add the original column names directly without any prefix\n",
    "            print(f\"passthrough columns={columns}\")\n",
    "            feature_names.extend(columns)\n",
    "        elif transformer == 'drop':\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                if isinstance(transformer, Pipeline) and isinstance(transformer[0],TfidfVectorizer):\n",
    "                    names=transformer[0].get_feature_names_out()\n",
    "                elif isinstance(transformer, Pipeline):\n",
    "                    last_step = transformer[-1]\n",
    "                    if hasattr(last_step, 'get_feature_names_out'):\n",
    "                        names = last_step.get_feature_names_out()\n",
    "                    else:\n",
    "                        names = columns\n",
    "                elif isinstance(transformer,CustomFunctionTransformer):\n",
    "                    names=transformer.cols_out\n",
    "                else:\n",
    "                    if hasattr(transformer, 'get_feature_names_out'):\n",
    "                        names = transformer.get_feature_names_out(columns)\n",
    "                    else:\n",
    "                        names = columns\n",
    "                feature_names.extend(names)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Add passthrough columns by their original names\n",
    "    feature_names.extend(passthrough_columns)\n",
    "    return feature_names\n",
    "\n",
    "def to_pandas(transformed,new_feature_names):\n",
    "    return pd.DataFrame(data=np.array(transformed), columns=new_feature_names)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "ab50300c",
   "metadata": {},
   "source": [
    "## import des données d'entrainement, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "id": "1aedeb6244ad0d5",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.616592700Z",
     "start_time": "2024-11-20T20:02:21.568206500Z"
    }
   },
   "source": [
    "data = pd.read_csv('../data/train.csv')\n",
    "#data.info()"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "b2b84a98fe3a93d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.618592300Z",
     "start_time": "2024-11-20T20:02:21.587588900Z"
    }
   },
   "source": [
    "dict(data.isnull().mean())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "{'PassengerId': 0.0,\n 'Survived': 0.0,\n 'Pclass': 0.0,\n 'Name': 0.0,\n 'Sex': 0.0,\n 'Age': 0.19865319865319866,\n 'SibSp': 0.0,\n 'Parch': 0.0,\n 'Ticket': 0.0,\n 'Fare': 0.0,\n 'Cabin': 0.7710437710437711,\n 'Embarked': 0.002244668911335578}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "ae555121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.661592800Z",
     "start_time": "2024-11-20T20:02:21.622589900Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop(\"Survived\", axis=1),\n",
    "    data[\"Survived\"],\n",
    "    test_size=0.3,\n",
    "    random_state=0,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "5d28ce0527f9dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.684117100Z",
     "start_time": "2024-11-20T20:02:21.664601Z"
    }
   },
   "source": [
    "df = X_train.copy()\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Pclass                                      Name     Sex  \\\n857          858       1                    Daly, Mr. Peter Denis     male   \n52            53       1  Harper, Mrs. Henry Sleeper (Myna Haxtun)  female   \n386          387       3           Goodwin, Master. Sidney Leonard    male   \n124          125       1               White, Mr. Percival Wayland    male   \n578          579       3          Caram, Mrs. Joseph (Maria Elias)  female   \n\n      Age  SibSp  Parch    Ticket     Fare Cabin Embarked  \n857  51.0      0      0    113055  26.5500   E17        S  \n52   49.0      1      0  PC 17572  76.7292   D33        C  \n386   1.0      5      2   CA 2144  46.9000   NaN        S  \n124  54.0      0      1     35281  77.2875   D26        S  \n578   NaN      1      0      2689  14.4583   NaN        C  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>857</th>\n      <td>858</td>\n      <td>1</td>\n      <td>Daly, Mr. Peter Denis</td>\n      <td>male</td>\n      <td>51.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>113055</td>\n      <td>26.5500</td>\n      <td>E17</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>53</td>\n      <td>1</td>\n      <td>Harper, Mrs. Henry Sleeper (Myna Haxtun)</td>\n      <td>female</td>\n      <td>49.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17572</td>\n      <td>76.7292</td>\n      <td>D33</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>387</td>\n      <td>3</td>\n      <td>Goodwin, Master. Sidney Leonard</td>\n      <td>male</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>CA 2144</td>\n      <td>46.9000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>125</td>\n      <td>1</td>\n      <td>White, Mr. Percival Wayland</td>\n      <td>male</td>\n      <td>54.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>35281</td>\n      <td>77.2875</td>\n      <td>D26</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>578</th>\n      <td>579</td>\n      <td>3</td>\n      <td>Caram, Mrs. Joseph (Maria Elias)</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2689</td>\n      <td>14.4583</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "409dbdaf",
   "metadata": {},
   "source": [
    "## Construction du pipeline : \n",
    "- d'abord les fonctions à appliquer à des colonnes spécifiques\n",
    "- puis les trsnformeurs de colonnes dans un ColumnTransformer, utilisant la classe Func_To_Transformer pour les fonctions spécifiques\n",
    "- puis le pipeline : ColumnTransformer+IterativeImputer+Modèle\n",
    "- ensuite on fait un \".fit().score()\" qui nous donne une idée de la performance de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3a9d5e669f7c0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.729116600Z",
     "start_time": "2024-11-20T20:02:21.690115900Z"
    }
   },
   "source": [
    "#helpers pour les colonnes\n",
    "\n",
    "def isNaN(sum):\n",
    "    return sum!=sum\n",
    "\n",
    "def sex(s):\n",
    "    return 1*(s==\"male\")\n",
    "\n",
    "def ticket(t):\n",
    "    try:\n",
    "        return int(t.split()[-1])\n",
    "    except:\n",
    "        return np.nan\n",
    "cab_nums=np.unique([c[0] for c in df.Cabin if not isNaN(c)])\n",
    "print(f\"cab_nums={cab_nums}\")\n",
    "def cabin(c):\n",
    "    try:\n",
    "        return np.array([[1*(v==c[0]) for v in cab_nums]+[int(c[1:])]])\n",
    "    except:\n",
    "        return np.array([[np.nan for _ in range (len(cab_nums)+1)]])\n",
    "ports=np.unique([c[0] for c in df.Embarked if not isNaN(c)])\n",
    "print(f\"ports={ports}\")\n",
    "def embarked(p):\n",
    "    try:\n",
    "        return np.array([[1*(v==p[0]) for v in ports]])\n",
    "    except:\n",
    "        return np.array([[np.nan for _ in range (len(ports))]])\n",
    "    \n",
    "def name(name : np.ndarray[str]) -> np.ndarray[str]:\n",
    "    name = np.array(name)\n",
    "    name = name.flatten()\n",
    "    name = [re.search(r' ([A-Za-z]+)\\.', n).group(1) for n in name]\n",
    "    rare_titles = ['Dr', 'Rev', 'Mlle', 'Major', 'Col', 'Countess', 'Capt', 'Ms', 'Sir', 'Lady', 'Mme', 'Don', 'Jonkheer']\n",
    "    nouveaux_noms = [x if x in ['Mr', 'Mrs', 'Miss', 'Master'] else 'Rare' for x in name]\n",
    "    return (nouveaux_noms)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cab_nums=['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T']\n",
      "ports=['C' 'Q' 'S']\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "89285167",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.763124300Z",
     "start_time": "2024-11-20T20:02:21.707114100Z"
    }
   },
   "source": [
    "cabin_transformer = Func_To_Transformer(cabin,[\"Cabin\"],[\"Pont_\"+v for v in cab_nums]+[\"NumCab\"])\n",
    "ticket_transformer = Func_To_Transformer(ticket,[\"Ticket\"],[\"Ticket\"])\n",
    "sex_transformer = Func_To_Transformer(sex,[\"Sex\"],[\"Sex\"])\n",
    "embarked_transformer = Func_To_Transformer(embarked,[\"Embarked\"],[\"Port_\"+p for p in ports]) #OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "name_transformer=Pipeline([('tfidf', TfidfVectorizer(max_features=100)),('to_dense', FunctionTransformer(lambda x: x.todense()))])"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:21.812634400Z",
     "start_time": "2024-11-20T20:02:21.722115100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NameExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, rare_titles=None):\n",
    "        self.rare_titles = rare_titles if rare_titles else ['Dr', 'Rev', 'Mlle', 'Major', 'Col', 'Countess', 'Capt', 'Ms', 'Sir', 'Lady', 'Mme', 'Don', 'Jonkheer']\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Aucun apprentissage nécessaire pour ce transformateur\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Si X est un DataFrame, accéder à la colonne sous forme de tableau\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.iloc[:, 0].values  # On prend la première colonne (Name)\n",
    "        \n",
    "        # Appliquer la transformation\n",
    "        titles = []\n",
    "        for name in X:\n",
    "            match = re.search(r' ([A-Za-z]+)\\.', name)\n",
    "            title = match.group(1) if match else 'Unknown'\n",
    "            title = title if title in ['Mr', 'Mrs', 'Miss', 'Master'] else 'Rare'\n",
    "            titles.append(title)\n",
    "        \n",
    "        # Retourner un tableau 2D compatible avec OneHotEncoder\n",
    "        return np.array(titles).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "name_pipeline = Pipeline([\n",
    "    ('name_extractor', NameExtractor()),  # Extraction des titres\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Encodage one-hot\n",
    "])"
   ],
   "id": "89b08629551f5a79",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "05fae555",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:40.850789200Z",
     "start_time": "2024-11-20T20:02:21.736115200Z"
    }
   },
   "source": [
    "GBC_pipeline = Pipeline([\n",
    "                        ('column_tranformer',ColumnTransformer(transformers=[\n",
    "                            ('cabin', cabin_transformer.get_transformer, cabin_transformer.cols_in),\n",
    "                            ('ticket', ticket_transformer.get_transformer, ticket_transformer.cols_in),\n",
    "                            ('sex', sex_transformer.get_transformer, sex_transformer.cols_in), \n",
    "                            ('embarked',embarked_transformer.get_transformer,embarked_transformer.cols_in),\n",
    "                            ('tdidf', name_transformer, 'Name'),\n",
    "                            ],\n",
    "                            remainder='passthrough')),\n",
    "                        ('to_array',FunctionTransformer(lambda x: x.A)),\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('imputer',IterativeImputer(estimator=Ridge(),max_iter=1000,random_state=0,tol=1e-3)),\n",
    "                        ('model',GradientBoostingClassifier())\n",
    "                        ],verbose=True)  \n",
    "GBC_score=GBC_pipeline.fit(X_train,y_train).score(X_test,y_test)\n",
    "GBC_score"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 5) Processing column_tranformer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing to_array, total=   0.0s\n",
      "[Pipeline] ............ (step 3 of 5) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........... (step 4 of 5) Processing imputer, total=  18.5s\n",
      "[Pipeline] ............. (step 5 of 5) Processing model, total=   0.4s\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.832089552238806"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "1097448c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:40.912311300Z",
     "start_time": "2024-11-20T20:02:40.850789200Z"
    }
   },
   "source": [
    "GBC_pipeline"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('column_tranformer',\n                 ColumnTransformer(remainder='passthrough',\n                                   transformers=[('cabin',\n                                                  CustomFunctionTransformer(cols_in=['Cabin'],\n                                                                            cols_out=['Pont_A',\n                                                                                      'Pont_B',\n                                                                                      'Pont_C',\n                                                                                      'Pont_D',\n                                                                                      'Pont_E',\n                                                                                      'Pont_F',\n                                                                                      'Pont_G',\n                                                                                      'Pont_T',\n                                                                                      'NumCab'],\n                                                                            func=<function Func_To_Transformer.get_transformer.<locals>.out_func at 0x00000164C53EEAF0>),\n                                                  ['Cabin']),\n                                                 ('ticket',\n                                                  C...\n                                                                   TfidfVectorizer(max_features=100)),\n                                                                  ('to_dense',\n                                                                   FunctionTransformer(func=<function <lambda> at 0x00000164A994CC10>))]),\n                                                  'Name')])),\n                ('to_array',\n                 FunctionTransformer(func=<function <lambda> at 0x00000164C563E160>)),\n                ('scaler', StandardScaler()),\n                ('imputer',\n                 IterativeImputer(estimator=Ridge(), max_iter=1000,\n                                  random_state=0)),\n                ('model', GradientBoostingClassifier())],\n         verbose=True)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;column_tranformer&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;cabin&#x27;,\n                                                  CustomFunctionTransformer(cols_in=[&#x27;Cabin&#x27;],\n                                                                            cols_out=[&#x27;Pont_A&#x27;,\n                                                                                      &#x27;Pont_B&#x27;,\n                                                                                      &#x27;Pont_C&#x27;,\n                                                                                      &#x27;Pont_D&#x27;,\n                                                                                      &#x27;Pont_E&#x27;,\n                                                                                      &#x27;Pont_F&#x27;,\n                                                                                      &#x27;Pont_G&#x27;,\n                                                                                      &#x27;Pont_T&#x27;,\n                                                                                      &#x27;NumCab&#x27;],\n                                                                            func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164C53EEAF0&gt;),\n                                                  [&#x27;Cabin&#x27;]),\n                                                 (&#x27;ticket&#x27;,\n                                                  C...\n                                                                   TfidfVectorizer(max_features=100)),\n                                                                  (&#x27;to_dense&#x27;,\n                                                                   FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000164A994CC10&gt;))]),\n                                                  &#x27;Name&#x27;)])),\n                (&#x27;to_array&#x27;,\n                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000164C563E160&gt;)),\n                (&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;imputer&#x27;,\n                 IterativeImputer(estimator=Ridge(), max_iter=1000,\n                                  random_state=0)),\n                (&#x27;model&#x27;, GradientBoostingClassifier())],\n         verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;column_tranformer&#x27;,\n                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                                   transformers=[(&#x27;cabin&#x27;,\n                                                  CustomFunctionTransformer(cols_in=[&#x27;Cabin&#x27;],\n                                                                            cols_out=[&#x27;Pont_A&#x27;,\n                                                                                      &#x27;Pont_B&#x27;,\n                                                                                      &#x27;Pont_C&#x27;,\n                                                                                      &#x27;Pont_D&#x27;,\n                                                                                      &#x27;Pont_E&#x27;,\n                                                                                      &#x27;Pont_F&#x27;,\n                                                                                      &#x27;Pont_G&#x27;,\n                                                                                      &#x27;Pont_T&#x27;,\n                                                                                      &#x27;NumCab&#x27;],\n                                                                            func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164C53EEAF0&gt;),\n                                                  [&#x27;Cabin&#x27;]),\n                                                 (&#x27;ticket&#x27;,\n                                                  C...\n                                                                   TfidfVectorizer(max_features=100)),\n                                                                  (&#x27;to_dense&#x27;,\n                                                                   FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000164A994CC10&gt;))]),\n                                                  &#x27;Name&#x27;)])),\n                (&#x27;to_array&#x27;,\n                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000164C563E160&gt;)),\n                (&#x27;scaler&#x27;, StandardScaler()),\n                (&#x27;imputer&#x27;,\n                 IterativeImputer(estimator=Ridge(), max_iter=1000,\n                                  random_state=0)),\n                (&#x27;model&#x27;, GradientBoostingClassifier())],\n         verbose=True)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">column_tranformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n                  transformers=[(&#x27;cabin&#x27;,\n                                 CustomFunctionTransformer(cols_in=[&#x27;Cabin&#x27;],\n                                                           cols_out=[&#x27;Pont_A&#x27;,\n                                                                     &#x27;Pont_B&#x27;,\n                                                                     &#x27;Pont_C&#x27;,\n                                                                     &#x27;Pont_D&#x27;,\n                                                                     &#x27;Pont_E&#x27;,\n                                                                     &#x27;Pont_F&#x27;,\n                                                                     &#x27;Pont_G&#x27;,\n                                                                     &#x27;Pont_T&#x27;,\n                                                                     &#x27;NumCab&#x27;],\n                                                           func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164C53EEAF0&gt;),\n                                 [&#x27;Cabin&#x27;]),\n                                (&#x27;ticket&#x27;,\n                                 CustomFunctionTransformer(cols_in=[&#x27;Ti...\n                                (&#x27;embarked&#x27;,\n                                 CustomFunctionTransformer(cols_in=[&#x27;Embarked&#x27;],\n                                                           cols_out=[&#x27;Port_C&#x27;,\n                                                                     &#x27;Port_Q&#x27;,\n                                                                     &#x27;Port_S&#x27;],\n                                                           func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164C5668DC0&gt;),\n                                 [&#x27;Embarked&#x27;]),\n                                (&#x27;tdidf&#x27;,\n                                 Pipeline(steps=[(&#x27;tfidf&#x27;,\n                                                  TfidfVectorizer(max_features=100)),\n                                                 (&#x27;to_dense&#x27;,\n                                                  FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000164A994CC10&gt;))]),\n                                 &#x27;Name&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cabin</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Cabin&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomFunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomFunctionTransformer(cols_in=[&#x27;Cabin&#x27;],\n                          cols_out=[&#x27;Pont_A&#x27;, &#x27;Pont_B&#x27;, &#x27;Pont_C&#x27;, &#x27;Pont_D&#x27;,\n                                    &#x27;Pont_E&#x27;, &#x27;Pont_F&#x27;, &#x27;Pont_G&#x27;, &#x27;Pont_T&#x27;,\n                                    &#x27;NumCab&#x27;],\n                          func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164C53EEAF0&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ticket</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Ticket&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomFunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomFunctionTransformer(cols_in=[&#x27;Ticket&#x27;], cols_out=[&#x27;Ticket&#x27;],\n                          func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164A994CA60&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">sex</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Sex&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomFunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomFunctionTransformer(cols_in=[&#x27;Sex&#x27;], cols_out=[&#x27;Sex&#x27;],\n                          func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164C5364820&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">embarked</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CustomFunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>CustomFunctionTransformer(cols_in=[&#x27;Embarked&#x27;],\n                          cols_out=[&#x27;Port_C&#x27;, &#x27;Port_Q&#x27;, &#x27;Port_S&#x27;],\n                          func=&lt;function Func_To_Transformer.get_transformer.&lt;locals&gt;.out_func at 0x00000164C5668DC0&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tdidf</label><div class=\"sk-toggleable__content\"><pre>Name</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=100)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000164A994CC10&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;PassengerId&#x27;, &#x27;Pclass&#x27;, &#x27;Age&#x27;, &#x27;SibSp&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x00000164C563E160&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">imputer: IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer(estimator=Ridge(), max_iter=1000, random_state=0)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "4679dfb7",
   "metadata": {},
   "source": [
    "### Un autre pipeline fondé sur un autre modèle et un autre estimateur dans l'imputer, pour le fun"
   ]
  },
  {
   "cell_type": "code",
   "id": "91b1658e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:41.727720600Z",
     "start_time": "2024-11-20T20:02:40.912311300Z"
    }
   },
   "source": [
    "RF_KNN_pipeline = Pipeline([\n",
    "                        ('column_tranformer',ColumnTransformer(transformers=[\n",
    "                            ('cabin', cabin_transformer.get_transformer, cabin_transformer.cols_in),\n",
    "                            ('ticket', ticket_transformer.get_transformer, ticket_transformer.cols_in),\n",
    "                            ('sex', sex_transformer.get_transformer, sex_transformer.cols_in), \n",
    "                            ('embarked',embarked_transformer.get_transformer,embarked_transformer.cols_in),\n",
    "                            ('name', name_pipeline, ['Name']),\n",
    "                            ],\n",
    "                            remainder='passthrough')),\n",
    "                        # ('to_array',FunctionTransformer(lambda x: x.A)),\n",
    "                        ('scaler',StandardScaler()),\n",
    "                        ('imputer',IterativeImputer(estimator=KNeighborsRegressor(n_neighbors=20),max_iter=10,random_state=0,tol=1e-3)),\n",
    "                        ('model',RandomForestClassifier())\n",
    "                        ])  \n",
    "RF_KNN_score=RF_KNN_pipeline.fit(X_train,y_train).score(X_test,y_test)\n",
    "RF_KNN_score"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": "0.8171641791044776"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "abd7d2bd",
   "metadata": {},
   "source": [
    "## On fait notre fichier de prédiction pour kaggle"
   ]
  },
  {
   "cell_type": "code",
   "id": "dad690c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:42.463255900Z",
     "start_time": "2024-11-20T20:02:41.729719800Z"
    }
   },
   "source": [
    "test=pd.read_csv('../data/test.csv')\n",
    "ypred=RF_KNN_pipeline.predict(test)\n",
    "submit=pd.DataFrame({'PassengerId':test['PassengerId'], 'Survived':ypred})\n",
    "submit.to_csv('/Users/lucascarpentier/submit.csv', index=False)"
   ],
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '\\Users\\lucascarpentier'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m ypred\u001B[38;5;241m=\u001B[39mRF_KNN_pipeline\u001B[38;5;241m.\u001B[39mpredict(test)\n\u001B[0;32m      3\u001B[0m submit\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mDataFrame({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPassengerId\u001B[39m\u001B[38;5;124m'\u001B[39m:test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPassengerId\u001B[39m\u001B[38;5;124m'\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSurvived\u001B[39m\u001B[38;5;124m'\u001B[39m:ypred})\n\u001B[1;32m----> 4\u001B[0m \u001B[43msubmit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/lucascarpentier/submit.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py:3902\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[0;32m   3891\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[0;32m   3893\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[0;32m   3894\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[0;32m   3895\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3899\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[0;32m   3900\u001B[0m )\n\u001B[1;32m-> 3902\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3903\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3904\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3905\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3906\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3907\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3908\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3909\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3910\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3911\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3912\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3913\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3914\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3916\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3918\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3919\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[0;32m   1131\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   1133\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[0;32m   1134\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[0;32m   1135\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1150\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[0;32m   1151\u001B[0m )\n\u001B[1;32m-> 1152\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[0;32m   1155\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    244\u001B[0m \u001B[38;5;124;03mCreate the writer & save.\u001B[39;00m\n\u001B[0;32m    245\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[1;32m--> 247\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    248\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    249\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    250\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    255\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[0;32m    256\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[0;32m    257\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[0;32m    258\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    263\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[0;32m    264\u001B[0m     )\n\u001B[0;32m    266\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:739\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    737\u001B[0m \u001B[38;5;66;03m# Only for write methods\u001B[39;00m\n\u001B[0;32m    738\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m is_path:\n\u001B[1;32m--> 739\u001B[0m     \u001B[43mcheck_parent_directory\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m compression:\n\u001B[0;32m    742\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzstd\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    743\u001B[0m         \u001B[38;5;66;03m# compression libraries do not like an explicit text-mode\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:604\u001B[0m, in \u001B[0;36mcheck_parent_directory\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    602\u001B[0m parent \u001B[38;5;241m=\u001B[39m Path(path)\u001B[38;5;241m.\u001B[39mparent\n\u001B[0;32m    603\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m parent\u001B[38;5;241m.\u001B[39mis_dir():\n\u001B[1;32m--> 604\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot save file into a non-existent directory: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mparent\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mOSError\u001B[0m: Cannot save file into a non-existent directory: '\\Users\\lucascarpentier'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "a6bf5b69",
   "metadata": {},
   "source": [
    "## On repart juste sur le preprocess (sans le dernier élément du pipeline qui est le modèle), pour explorer l'importance des features"
   ]
  },
  {
   "cell_type": "code",
   "id": "8bd5b7fa",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-20T20:02:42.462256600Z"
    }
   },
   "source": [
    "avant_model=GBC_pipeline[:-1].fit(X_train,y_train)\n",
    "new_columns=get_feature_names_from_column_transformer(avant_model[0], X_train.columns.to_list())\n",
    "train=to_pandas(avant_model.transform(X_train),new_columns)\n",
    "test=to_pandas(avant_model.transform(X_test),new_columns)\n",
    "train.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "229556ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:42.464256800Z",
     "start_time": "2024-11-20T20:02:42.464256800Z"
    }
   },
   "source": [
    "plot_correlation(pd.concat([y_train,train],axis=1),False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3176c43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:42.468257900Z",
     "start_time": "2024-11-20T20:02:42.466257500Z"
    }
   },
   "source": [
    "#on choisit un modèle qui a l'attribut \"feature_importances_\"\n",
    "mon_modele=GradientBoostingClassifier()\n",
    "mon_modele.fit(train,y_train)\n",
    "importances=mon_modele.feature_importances_\n",
    "importances=dict(sorted(zip(train.columns,importances),key=lambda x:x[1],reverse=True))\n",
    "plt.figure(figsize=(16,3))\n",
    "plt.bar(importances.keys(),importances.values(),alpha=0.5)\n",
    "plt.xticks(rotation=60)\n",
    "plt.title(f\"Importances, score du modèle sur le train : {mon_modele.score(test,y_test)}\")\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9790ca34",
   "metadata": {},
   "source": [
    "## Evolution de l'importance des features et du score en fonction de l'ensemble des colonnes retenues"
   ]
  },
  {
   "cell_type": "code",
   "id": "73a044f9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-20T20:02:42.467258500Z"
    }
   },
   "source": [
    "#on peut décider de laisser tomber les features qui ont une importance en-deçà d'un certain seuil\n",
    "new_cols=[col for col in train.columns if importances[col]>0.01]\n",
    "n_importances={k:v for k,v in importances.items() if k in new_cols}\n",
    "new_score=mon_modele.fit(train[new_cols],y_train).score(test[new_cols],y_test)\n",
    "nn_importances=mon_modele.feature_importances_\n",
    "nn_importances=dict(sorted(zip(new_cols,nn_importances),key=lambda x:x[1],reverse=True))\n",
    "print(f\"score en enlevant les features moins importantes ={new_score}\")\n",
    "plt.figure(figsize=(16,3))\n",
    "plt.bar(n_importances.keys(),n_importances.values(),alpha=0.5,color='g',label='original')\n",
    "plt.bar(nn_importances.keys(),nn_importances.values(),alpha=0.5,color='y',label=\"restricted\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=60)\n",
    "plt.title(f\"Importances, score du modèle sur le test : {new_score}\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5bf6db83",
   "metadata": {},
   "source": [
    "## Enregistrement de nouveaux csv pour test et train pour réutiliser ailleurs"
   ]
  },
  {
   "cell_type": "code",
   "id": "08bcc258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T20:02:42.479263Z",
     "start_time": "2024-11-20T20:02:42.469257800Z"
    }
   },
   "source": [
    "ndata=data.drop(columns=[\"Survived\"])\n",
    "to_pandas(GBC_pipeline[:-1].transform(pd.read_csv('../data/test.csv')),new_columns).to_csv('ntest.csv',index=False)\n",
    "ntrain=to_pandas(GBC_pipeline[:-1].transform(ndata),new_columns)\n",
    "ntrain[\"Survived\"]=data[\"Survived\"]\n",
    "ntrain.to_csv('ntrain.csv',index=False)\n",
    "print(f\"ntrain.shape={ntrain.shape}\")\n",
    "ntrain.head()\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_environnement1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
